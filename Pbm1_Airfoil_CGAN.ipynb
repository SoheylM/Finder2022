{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0edc4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from tensorflow_docs.vis import embed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e7112a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700eecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "57db02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU memory growth so that I can still work on my PC with other GPU hungry apps..\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpu_devices:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpu_devices[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set at program startup\n",
    "    print(e)\n",
    "\n",
    "# To use bloody mixed precision on my GPUs\n",
    "#tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3077dc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data my man\n",
    "airfoils_opt_995 = np.load('./data/airfoils_opt_995.npy')\n",
    "aoas_opt_995     = np.load('./data/aoas_opt_995.npy')\n",
    "inp_paras_995    = np.load('./data/inp_paras_995.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "90abb4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 192, 2)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 995 airfoils, 192 points, 2 for x and y\n",
    "airfoils_opt_995.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d6006f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995,)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal angle of attack\n",
    "aoas_opt_995.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "75666034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 3)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ma, Re, Lift\n",
    "inp_paras_995.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14a887",
   "metadata": {},
   "source": [
    "## Defining the inputs X and outputs Y of the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "010e467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 384)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = inp_paras_995\n",
    "Y = airfoils_opt_995\n",
    "\n",
    "# Reshaping Y to get a 2D array\n",
    "nsamples, nx, ny = Y.shape\n",
    "Y = Y.reshape((nsamples,nx*ny))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7113ef4",
   "metadata": {},
   "source": [
    "## Split in training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "753f4be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler() #GaussRankScaler() #QuantileTransformer(output_distribution='normal') #PowerTransformer() #MinMaxScaler(feature_range=(-1, 1)) # StandardScaler()\n",
    "scaler_y = StandardScaler() #GaussRankScaler() #QuantileTransformer(output_distribution='normal') #PowerTransformer() #MinMaxScaler(feature_range=(-1, 1)) # StandardScaler() #MinMaxScaler()\n",
    "\n",
    "# Split randomly the data into test and validation sets to avoid overfitting during training.\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.20, random_state=1)\n",
    "#X_valid, X_test, Y_valid, Y_test   = train_test_split(X_valid, Y_valid, test_size=0.5, random_state=1)\n",
    "\n",
    "# Fit the scalers on the training data only!\n",
    "scaler_x.fit(X_train)\n",
    "scaler_y.fit(Y_train)\n",
    "\n",
    "# Standardize the sets\n",
    "x_train = scaler_x.transform(X_train).astype(np.float32)\n",
    "x_valid = scaler_x.transform(X_valid).astype(np.float32)\n",
    "#x_test  = scaler_x.transform(X_test).astype(np.float32)\n",
    "\n",
    "y_train = scaler_y.transform(Y_train).astype(np.float32)\n",
    "y_valid = scaler_y.transform(Y_valid).astype(np.float32)\n",
    "#y_test  = scaler_y.transform(Y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c2756",
   "metadata": {},
   "source": [
    "## Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "767f876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "BATCH_SIZE = batch_size\n",
    "num_channels = Y.shape[1] #1\n",
    "num_classes = 0 #10\n",
    "image_size = 28\n",
    "latent_dim = X.shape[1] #128\n",
    "n_neurons = 30\n",
    "noise_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25dcca0",
   "metadata": {},
   "source": [
    "## Loading the MNIST dataset and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e3fbea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training airfoils: (896, 384)\n",
      "Shape of training op: (896, 3)\n"
     ]
    }
   ],
   "source": [
    "# labels -> op\n",
    "# digits -> airfoils\n",
    "all_op = np.concatenate([x_train, x_test])\n",
    "all_airfoils = np.concatenate([y_train, y_test])\n",
    "#nx, ny = all_airfoils.shape\n",
    "#all_airfoils = np.reshape(all_airfoils,(nx,ny,1))\n",
    "\n",
    "# Create tf.data.Dataset.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_airfoils, all_op))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training airfoils: {all_airfoils.shape}\")\n",
    "print(f\"Shape of training op: {all_op.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ce31e",
   "metadata": {},
   "source": [
    "## Calculating the number of input channel for the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "091888ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 384\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f485f9a",
   "metadata": {},
   "source": [
    "## Creating the discriminator and generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7c863f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer(input_shape=(discriminator_in_channels,)),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(n_neurons),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(n_neurons),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(n_neurons),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(1),\n",
    "        #layers.Softmax()\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "activation = 'relu'\n",
    "k_ini       = 'he_uniform'\n",
    "L2_pen     = 1e-6\n",
    "nb_neurons = 100\n",
    "nb_layers  = 5\n",
    "optimizer='Adam'\n",
    "\n",
    "model_ANN = Sequential()\n",
    "\n",
    "# input layer\n",
    "model_ANN.add(Dense(nb_neurons, input_dim=(discriminator_in_channels), activation=activation, kernel_initializer=k_ini,dtype=tf.float32))\n",
    "\n",
    "# hidden layers\n",
    "for i in range(nb_layers):\n",
    "    if i == 0:\n",
    "        if optimizer == 'NGA' or optimizer == 'CMA':\n",
    "            dense_layer = Dense(nb_neurons, activation=activation, kernel_initializer=k_ini,dtype=tf.float32)(input_layer)\n",
    "        else:\n",
    "            model_ANN.add(Dense(nb_neurons, activation=activation, kernel_initializer=k_ini, kernel_regularizer=l2(L2_pen), dtype=tf.float32))\n",
    "    elif i == (nb_layers-1): # Last layer\n",
    "        if optimizer == 'NGA' or optimizer == 'CMA':\n",
    "            dense_layer = Dense(nb_neurons, activation=activation, kernel_initializer=k_ini,dtype=tf.float32)(dense_layer)\n",
    "        else:\n",
    "            model_ANN.add(Dense(nb_neurons, activation=activation, kernel_initializer=k_ini, kernel_regularizer=l2(L2_pen), dtype=tf.float32))\n",
    "    else:\n",
    "        if optimizer == 'NGA' or optimizer == 'CMA':\n",
    "            dense_layer = Dense(nb_neurons, activation=activation, kernel_initializer=k_ini,dtype=tf.float32)(dense_layer)\n",
    "        else:\n",
    "            model_ANN.add(Dense(nb_neurons, activation=activation, kernel_initializer=k_ini, kernel_regularizer=l2(L2_pen), dtype=tf.float32))\n",
    "# output layer\n",
    "model_ANN.add(Dense(1, dtype=tf.float32))\n",
    "\n",
    "d_model = model_ANN\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels+noise_dim,)),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(n_neurons),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(n_neurons),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(num_channels),\n",
    "        layers.ReLU(),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "model_ANN = Sequential()\n",
    "\n",
    "# input layer\n",
    "model_ANN.add(Dense(nb_neurons, input_dim=(generator_in_channels+noise_dim), activation=activation, kernel_initializer=k_ini,dtype=tf.float32))\n",
    "\n",
    "# hidden layers\n",
    "for i in range(nb_layers):\n",
    "    if i == 0:\n",
    "        if optimizer == 'NGA' or optimizer == 'CMA':\n",
    "            dense_layer = Dense(nb_neurons, activation=activation, kernel_initializer=k_ini,dtype=tf.float32)(input_layer)\n",
    "        else:\n",
    "            model_ANN.add(Dense(nb_neurons, activation=activation, kernel_initializer=k_ini, kernel_regularizer=l2(L2_pen), dtype=tf.float32))\n",
    "    elif i == (nb_layers-1): # Last layer\n",
    "        if optimizer == 'NGA' or optimizer == 'CMA':\n",
    "            dense_layer = Dense(nb_neurons, activation=activation, kernel_initializer=k_ini,dtype=tf.float32)(dense_layer)\n",
    "        else:\n",
    "            model_ANN.add(Dense(nb_neurons, activation=activation, kernel_initializer=k_ini, kernel_regularizer=l2(L2_pen), dtype=tf.float32))\n",
    "    else:\n",
    "        if optimizer == 'NGA' or optimizer == 'CMA':\n",
    "            dense_layer = Dense(nb_neurons, activation=activation, kernel_initializer=k_ini,dtype=tf.float32)(dense_layer)\n",
    "        else:\n",
    "            model_ANN.add(Dense(nb_neurons, activation=activation, kernel_initializer=k_ini, kernel_regularizer=l2(L2_pen), dtype=tf.float32))\n",
    "# output layer\n",
    "model_ANN.add(Dense(num_channels, dtype=tf.float32))\n",
    "\n",
    "g_model = model_ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821029ed",
   "metadata": {},
   "source": [
    "## Creating a ConditionalGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "75f591b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass ConditionalGAN(keras.Model):\\n    def __init__(self, discriminator, generator, latent_dim):\\n        super(ConditionalGAN, self).__init__()\\n        self.discriminator = discriminator\\n        self.generator = generator\\n        self.latent_dim = latent_dim\\n        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\\n        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\\n\\n    @property\\n    def metrics(self):\\n        return [self.gen_loss_tracker, self.disc_loss_tracker]\\n\\n    def compile(self, d_optimizer, g_optimizer, loss_fn):\\n        super(ConditionalGAN, self).compile()\\n        self.d_optimizer = d_optimizer\\n        self.g_optimizer = g_optimizer\\n        self.loss_fn = loss_fn\\n    \\n    # all good till here\\n    def train_step(self, data):\\n        # Unpack the data.\\n        # real_images -> real_airfoils\\n        # one_hot_labels -> op\\n        real_airfoils, op = data\\n\\n        # Sample random points in the latent space and concatenate the labels.\\n        # This is for the generator.\\n        batch_size = tf.shape(real_airfoils)[0]\\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), dtype=tf.float32)\\n        random_vector_labels = tf.concat(\\n            [random_latent_vectors, op], axis=1\\n        )\\n        print(\\'random_vector_labels shape\\', random_vector_labels.shape)\\n        # all good till here\\n        \\n        # Decode the noise (guided by labels) to fake airfoils.\\n        generated_airfoils = self.generator(random_vector_labels)\\n        print(\\'generated_airfoils shape\\', generated_airfoils.shape)\\n\\n        # Combine them with real airfoils. \\n        fake_airfoils = generated_airfoils\\n        print(\\'fake_airfoils shape\\', fake_airfoils.shape)\\n        real_airfoils = real_airfoils\\n        print(\\'real_airfoils shape\\', real_airfoils.shape)\\n        combined_airfoils = tf.concat(\\n            [fake_airfoils, real_airfoils], axis=0\\n        )\\n        print(\\'combined_airfoils shape\\', combined_airfoils.shape)\\n\\n        # Assemble labels discriminating real from fake images.\\n        labels = tf.concat(\\n            [tf.ones((batch_size, 1), dtype=tf.float32), tf.zeros((batch_size, 1), dtype=tf.float32)], axis=0\\n        )\\n        print(\\'tf.ones((batch_size, 1)\\', tf.ones((batch_size, 1)))\\n        print(\\'labels shape\\', labels.shape)\\n\\n        # Train the discriminator.\\n        with tf.GradientTape() as tape:\\n            predictions = self.discriminator(combined_airfoils)\\n            print(\\'predictions shape\\', predictions.shape)\\n            d_loss = self.loss_fn(labels, predictions)\\n        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\\n        self.d_optimizer.apply_gradients(\\n            zip(grads, self.discriminator.trainable_weights)\\n        )\\n\\n        # Sample random points in the latent space.\\n        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), dtype=tf.float32)\\n        print(\\'random_latent_vectors shape\\', random_latent_vectors.shape)\\n        random_vector_labels = tf.concat(\\n            [random_latent_vectors, op], axis=1\\n        )\\n        print(\\'random_vector_labels shape\\', random_vector_labels.shape)\\n\\n        # Assemble labels that say \"all real airfoils\".\\n        misleading_labels = tf.zeros((batch_size, 1))\\n        print(\\'misleading_labels shape\\', misleading_labels.shape)\\n\\n        # Train the generator (note that we should *not* update the weights\\n        # of the discriminator)!\\n        with tf.GradientTape() as tape:\\n            fake_airfoils = self.generator(random_vector_labels)\\n            print(\\'fake_airfoils shape\\', fake_airfoils.shape)\\n            #fake_image_and_labels = tf.concat([fake_airfoils, image_one_hot_labels], -1)\\n            predictions = self.discriminator(fake_airfoils)\\n            print(\\'predictions shape\\', predictions.shape)\\n            g_loss = self.loss_fn(misleading_labels, predictions)\\n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\\n        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\\n\\n        # Monitor loss.\\n        self.gen_loss_tracker.update_state(g_loss)\\n        self.disc_loss_tracker.update_state(d_loss)\\n        return {\\n            \"g_loss\": self.gen_loss_tracker.result(),\\n            \"d_loss\": self.disc_loss_tracker.result(),\\n        }\\n\\n'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(ConditionalGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(ConditionalGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    # all good till here\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        # real_images -> real_airfoils\n",
    "        # one_hot_labels -> op\n",
    "        real_airfoils, op = data\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_airfoils)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), dtype=tf.float32)\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, op], axis=1\n",
    "        )\n",
    "        print('random_vector_labels shape', random_vector_labels.shape)\n",
    "        # all good till here\n",
    "        \n",
    "        # Decode the noise (guided by labels) to fake airfoils.\n",
    "        generated_airfoils = self.generator(random_vector_labels)\n",
    "        print('generated_airfoils shape', generated_airfoils.shape)\n",
    "\n",
    "        # Combine them with real airfoils. \n",
    "        fake_airfoils = generated_airfoils\n",
    "        print('fake_airfoils shape', fake_airfoils.shape)\n",
    "        real_airfoils = real_airfoils\n",
    "        print('real_airfoils shape', real_airfoils.shape)\n",
    "        combined_airfoils = tf.concat(\n",
    "            [fake_airfoils, real_airfoils], axis=0\n",
    "        )\n",
    "        print('combined_airfoils shape', combined_airfoils.shape)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1), dtype=tf.float32), tf.zeros((batch_size, 1), dtype=tf.float32)], axis=0\n",
    "        )\n",
    "        print('tf.ones((batch_size, 1)', tf.ones((batch_size, 1)))\n",
    "        print('labels shape', labels.shape)\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_airfoils)\n",
    "            print('predictions shape', predictions.shape)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), dtype=tf.float32)\n",
    "        print('random_latent_vectors shape', random_latent_vectors.shape)\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, op], axis=1\n",
    "        )\n",
    "        print('random_vector_labels shape', random_vector_labels.shape)\n",
    "\n",
    "        # Assemble labels that say \"all real airfoils\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "        print('misleading_labels shape', misleading_labels.shape)\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_airfoils = self.generator(random_vector_labels)\n",
    "            print('fake_airfoils shape', fake_airfoils.shape)\n",
    "            #fake_image_and_labels = tf.concat([fake_airfoils, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_airfoils)\n",
    "            print('predictions shape', predictions.shape)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "10d10ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = discriminator_extra_steps\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_airfoils, fake_airfoils):\n",
    "        \"\"\"Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated airfoil\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, tf.shape(real_airfoils)[1]], 0.0, 1.0)\n",
    "        diff = fake_airfoils - real_airfoils\n",
    "        interpolated = real_airfoils + alpha * diff\n",
    "\n",
    "        # good till here\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \n",
    "        real_airfoils, op = data\n",
    "        \n",
    "        if isinstance(real_airfoils, tuple):\n",
    "            real_airfoils = real_airfoils[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_airfoils)[0]\n",
    "\n",
    "        # For each batch, we are going to perform the\n",
    "        # following steps as laid out in the original paper:\n",
    "        # 1. Train the generator and get the generator loss\n",
    "        # 2. Train the discriminator and get the discriminator loss\n",
    "        # 3. Calculate the gradient penalty\n",
    "        # 4. Multiply this gradient penalty with a constant weight factor\n",
    "        # 5. Add the gradient penalty to the discriminator loss\n",
    "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
    "\n",
    "        # Train the discriminator first. The original paper recommends training\n",
    "        # the discriminator for `x` more steps (typically 5) as compared to\n",
    "        # one step of the generator. Here we will train it for 3 extra steps\n",
    "        # as compared to 5 to reduce the training time.\n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), dtype=tf.float32)\n",
    "            random_vector_labels = tf.concat(\n",
    "                [random_latent_vectors, op], axis=1\n",
    "            )\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_airfoils = self.generator(random_vector_labels, training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_airfoils, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_airfoils, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = self.d_loss_fn(real_afl=real_logits, fake_afl=fake_logits)\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_airfoils, fake_airfoils)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "        #good till here\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim), dtype=tf.float32)\n",
    "        random_vector_labels = tf.concat([random_latent_vectors, op], axis=1)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_airfoils = self.generator(random_vector_labels, training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_afl_logits = self.discriminator(generated_airfoils, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_afl_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2bab2c",
   "metadata": {},
   "source": [
    "## Training the Wasserstein Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "be1eae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56/56 [==============================] - 5s 47ms/step - d_loss: -4.4618 - g_loss: 0.4247\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 2s 43ms/step - d_loss: -13.5327 - g_loss: -0.2401\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 2s 42ms/step - d_loss: -19.7167 - g_loss: 0.0781\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 2s 43ms/step - d_loss: -21.6026 - g_loss: -0.2202\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 2s 43ms/step - d_loss: -21.1557 - g_loss: -0.0240\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 2s 43ms/step - d_loss: -21.2126 - g_loss: 1.2294\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 2s 42ms/step - d_loss: -21.7847 - g_loss: 1.4247\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 2s 40ms/step - d_loss: -22.5901 - g_loss: 1.8810\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 2s 41ms/step - d_loss: -22.7857 - g_loss: 1.8295\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 2s 42ms/step - d_loss: -21.9809 - g_loss: 0.9572\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 2s 42ms/step - d_loss: -20.6361 - g_loss: 0.3973\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 2s 40ms/step - d_loss: -19.7216 - g_loss: 1.5758\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 2s 37ms/step - d_loss: -20.3478 - g_loss: 3.0897\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 2s 37ms/step - d_loss: -20.5737 - g_loss: 4.8516\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 2s 38ms/step - d_loss: -21.5193 - g_loss: 4.2387\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 2s 36ms/step - d_loss: -20.6098 - g_loss: 0.2720\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 2s 34ms/step - d_loss: -16.2458 - g_loss: -3.4718\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 2s 37ms/step - d_loss: -13.4162 - g_loss: -3.6748\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 2s 35ms/step - d_loss: -12.4052 - g_loss: -0.4967\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 2s 35ms/step - d_loss: -12.3382 - g_loss: 1.3073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x218cbdcc1f0>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate the optimizer for both networks\n",
    "# (learning_rate=0.0002, beta_1=0.5 are recommended)\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0001, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0001, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "# Define the loss functions for the discriminator,\n",
    "# which should be (fake_loss - real_loss).\n",
    "# We will add the gradient penalty later to this loss function.\n",
    "def discriminator_loss(real_afl, fake_afl):\n",
    "    real_loss = tf.reduce_mean(real_afl)\n",
    "    fake_loss = tf.reduce_mean(fake_afl)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_afl):\n",
    "    return -tf.reduce_mean(fake_afl)\n",
    "\n",
    "\n",
    "# Set the number of epochs for trainining.\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "# Get the wgan model\n",
    "wgan = WGAN(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=noise_dim,\n",
    "    discriminator_extra_steps=3,\n",
    ")\n",
    "\n",
    "# Compile the wgan model\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "wgan.fit(dataset, batch_size=BATCH_SIZE, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.00003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.00003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=50)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384da28b",
   "metadata": {},
   "source": [
    "## Predict with the generator and Plot the airfoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = wgan.generator #cond_gan.generator\n",
    "\n",
    "for i in range(30):\n",
    "    # generate noise\n",
    "    interpolation_noise = tf.random.normal(shape=(1, noise_dim))\n",
    "    # concatenate it with a test row\n",
    "    n_row = i\n",
    "    input_test=tf.concat([interpolation_noise,np.reshape(x_test[n_row,:],(1,-1))], axis=1)\n",
    "    # send it to trained_gen\n",
    "    Y_gen = scaler_y.inverse_transform(trained_gen(input_test))\n",
    "    Y_gen = np.reshape(Y_gen,(1,-1,2))\n",
    "    # Reshape the test airfoil\n",
    "    Y_test_row = Y_valid[n_row,:]\n",
    "    Y_test_row = np.reshape(Y_test_row,(1,-1,2))\n",
    "    interpolation_noise\n",
    "\n",
    "    plt.scatter(Y_gen[:,:,0], Y_gen[:,:,1],label ='Generated airfoil')\n",
    "    plt.scatter(Y_test_row[:,:,0], Y_test_row[:,:,1],label ='True airfoil')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ff5c7f",
   "metadata": {},
   "source": [
    "## Plot the airfoil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "cf5d444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y_gen[:,:,0], Y_gen[:,:,1],label ='Generated airfoil')\n",
    "plt.scatter(Y_test_row[:,:,0], Y_test_row[:,:,1],label ='True airfoil')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7eabe371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 9.99510000e-01,  2.78198396e-03],\n",
       "        [ 9.98396000e-01,  3.19744988e-03],\n",
       "        [ 9.78435000e-01,  7.50774174e-03],\n",
       "        [ 9.71960000e-01,  8.40908626e-03],\n",
       "        [ 9.55773000e-01,  1.06889448e-02],\n",
       "        [ 9.46407000e-01,  1.22246440e-02],\n",
       "        [ 9.31472000e-01,  1.49534052e-02],\n",
       "        [ 9.22626000e-01,  1.66457820e-02],\n",
       "        [ 9.08979000e-01,  1.92692711e-02],\n",
       "        [ 8.98393000e-01,  2.12867056e-02],\n",
       "        [ 8.83992000e-01,  2.39937183e-02],\n",
       "        [ 8.71244000e-01,  2.63603175e-02],\n",
       "        [ 8.59387000e-01,  2.85368734e-02],\n",
       "        [ 8.48274000e-01,  3.05538571e-02],\n",
       "        [ 8.33516000e-01,  3.31892342e-02],\n",
       "        [ 8.24610000e-01,  3.47498351e-02],\n",
       "        [ 8.10890000e-01,  3.70980237e-02],\n",
       "        [ 8.03007000e-01,  3.84121116e-02],\n",
       "        [ 7.90253000e-01,  4.04774902e-02],\n",
       "        [ 7.83746000e-01,  4.14986187e-02],\n",
       "        [ 7.69634000e-01,  4.36314231e-02],\n",
       "        [ 7.59644000e-01,  4.50682572e-02],\n",
       "        [ 7.45779000e-01,  4.69562950e-02],\n",
       "        [ 7.37747000e-01,  4.79903767e-02],\n",
       "        [ 7.26486000e-01,  4.93644092e-02],\n",
       "        [ 7.14360000e-01,  5.07421376e-02],\n",
       "        [ 7.03557000e-01,  5.18788724e-02],\n",
       "        [ 6.92376000e-01,  5.29629539e-02],\n",
       "        [ 6.81856000e-01,  5.38982018e-02],\n",
       "        [ 6.70222000e-01,  5.48368876e-02],\n",
       "        [ 6.55423000e-01,  5.58842587e-02],\n",
       "        [ 6.45244000e-01,  5.65119998e-02],\n",
       "        [ 6.34330000e-01,  5.71014677e-02],\n",
       "        [ 6.25124000e-01,  5.75334804e-02],\n",
       "        [ 6.08671000e-01,  5.81592117e-02],\n",
       "        [ 6.00288000e-01,  5.84085147e-02],\n",
       "        [ 5.88026000e-01,  5.86918204e-02],\n",
       "        [ 5.76328000e-01,  5.88740193e-02],\n",
       "        [ 5.66240000e-01,  5.89673284e-02],\n",
       "        [ 5.60422000e-01,  5.89931458e-02],\n",
       "        [ 5.48029000e-01,  5.89885292e-02],\n",
       "        [ 5.30991000e-01,  5.88510546e-02],\n",
       "        [ 5.20439000e-01,  5.86944286e-02],\n",
       "        [ 5.09843000e-01,  5.84866803e-02],\n",
       "        [ 5.02260000e-01,  5.83073839e-02],\n",
       "        [ 4.90078000e-01,  5.79721620e-02],\n",
       "        [ 4.76900000e-01,  5.75450685e-02],\n",
       "        [ 4.66364000e-01,  5.71604518e-02],\n",
       "        [ 4.55124000e-01,  5.67112713e-02],\n",
       "        [ 4.43746000e-01,  5.62177136e-02],\n",
       "        [ 4.35327000e-01,  5.58292519e-02],\n",
       "        [ 4.25905000e-01,  5.53719838e-02],\n",
       "        [ 4.16788000e-01,  5.49102631e-02],\n",
       "        [ 4.04782000e-01,  5.42734557e-02],\n",
       "        [ 3.93649000e-01,  5.36575817e-02],\n",
       "        [ 3.83872000e-01,  5.30965500e-02],\n",
       "        [ 3.71202000e-01,  5.23442145e-02],\n",
       "        [ 3.59146000e-01,  5.16044084e-02],\n",
       "        [ 3.45674000e-01,  5.07519456e-02],\n",
       "        [ 3.37979000e-01,  5.02527533e-02],\n",
       "        [ 3.25990000e-01,  4.94586595e-02],\n",
       "        [ 3.11857000e-01,  4.84987563e-02],\n",
       "        [ 3.02123000e-01,  4.78214231e-02],\n",
       "        [ 2.89628000e-01,  4.69331328e-02],\n",
       "        [ 2.77800000e-01,  4.60717277e-02],\n",
       "        [ 2.64356000e-01,  4.50682541e-02],\n",
       "        [ 2.49831000e-01,  4.39505568e-02],\n",
       "        [ 2.40436000e-01,  4.32075580e-02],\n",
       "        [ 2.29937000e-01,  4.23577876e-02],\n",
       "        [ 2.14372000e-01,  4.10542898e-02],\n",
       "        [ 1.98922000e-01,  3.97031875e-02],\n",
       "        [ 1.90221000e-01,  3.89125178e-02],\n",
       "        [ 1.76827000e-01,  3.76511803e-02],\n",
       "        [ 1.65032000e-01,  3.64871101e-02],\n",
       "        [ 1.50600000e-01,  3.49879426e-02],\n",
       "        [ 1.42453000e-01,  3.41004794e-02],\n",
       "        [ 1.28593000e-01,  3.25094573e-02],\n",
       "        [ 1.16979000e-01,  3.10888935e-02],\n",
       "        [ 1.06362000e-01,  2.97092898e-02],\n",
       "        [ 9.74520000e-02,  2.84826292e-02],\n",
       "        [ 8.82500000e-02,  2.71401910e-02],\n",
       "        [ 7.79400000e-02,  2.55303089e-02],\n",
       "        [ 7.02370000e-02,  2.42418861e-02],\n",
       "        [ 6.15360000e-02,  2.26854389e-02],\n",
       "        [ 5.27950000e-02,  2.09898578e-02],\n",
       "        [ 4.33340000e-02,  1.89712898e-02],\n",
       "        [ 3.57740000e-02,  1.71830962e-02],\n",
       "        [ 2.81510000e-02,  1.51706834e-02],\n",
       "        [ 2.18150000e-02,  1.32812459e-02],\n",
       "        [ 1.55120000e-02,  1.11138393e-02],\n",
       "        [ 1.07380000e-02,  9.17347874e-03],\n",
       "        [ 6.53400000e-03,  7.08835994e-03],\n",
       "        [ 3.23200000e-03,  4.92527442e-03],\n",
       "        [ 1.50100000e-03,  3.30308200e-03],\n",
       "        [ 4.99000000e-04,  1.82285155e-03],\n",
       "        [ 1.38000000e-04,  8.35854471e-04],\n",
       "        [ 0.00000000e+00, -1.79000000e-04],\n",
       "        [ 1.08000000e-04, -1.57941839e-03],\n",
       "        [ 3.61000000e-04, -2.49704332e-03],\n",
       "        [ 8.46000000e-04, -3.51641833e-03],\n",
       "        [ 1.57600000e-03, -4.51774130e-03],\n",
       "        [ 3.01800000e-03, -5.83085020e-03],\n",
       "        [ 4.91200000e-03, -6.99610634e-03],\n",
       "        [ 7.46400000e-03, -8.10496097e-03],\n",
       "        [ 1.16690000e-02, -9.36283684e-03],\n",
       "        [ 1.63190000e-02, -1.03208304e-02],\n",
       "        [ 2.30750000e-02, -1.12795615e-02],\n",
       "        [ 3.12190000e-02, -1.20519645e-02],\n",
       "        [ 3.96740000e-02, -1.25920950e-02],\n",
       "        [ 5.00430000e-02, -1.30292934e-02],\n",
       "        [ 5.96000000e-02, -1.32860728e-02],\n",
       "        [ 7.06680000e-02, -1.34633053e-02],\n",
       "        [ 8.28490000e-02, -1.35500539e-02],\n",
       "        [ 9.27910000e-02, -1.35576715e-02],\n",
       "        [ 1.04467000e-01, -1.35103265e-02],\n",
       "        [ 1.16544000e-01, -1.34101187e-02],\n",
       "        [ 1.29131000e-01, -1.32597268e-02],\n",
       "        [ 1.39979000e-01, -1.30975894e-02],\n",
       "        [ 1.53144000e-01, -1.28659688e-02],\n",
       "        [ 1.63779000e-01, -1.26553296e-02],\n",
       "        [ 1.74894000e-01, -1.24138519e-02],\n",
       "        [ 1.86440000e-01, -1.21426992e-02],\n",
       "        [ 2.01436000e-01, -1.17608057e-02],\n",
       "        [ 2.11406000e-01, -1.14899929e-02],\n",
       "        [ 2.23233000e-01, -1.11523174e-02],\n",
       "        [ 2.34587000e-01, -1.08121089e-02],\n",
       "        [ 2.49365000e-01, -1.03466858e-02],\n",
       "        [ 2.58829000e-01, -1.00358330e-02],\n",
       "        [ 2.74554000e-01, -9.49738807e-03],\n",
       "        [ 2.84282000e-01, -9.15255963e-03],\n",
       "        [ 3.00059000e-01, -8.57208080e-03],\n",
       "        [ 3.13210000e-01, -8.06993833e-03],\n",
       "        [ 3.26871000e-01, -7.53177344e-03],\n",
       "        [ 3.40906000e-01, -6.96272594e-03],\n",
       "        [ 3.53355000e-01, -6.44313730e-03],\n",
       "        [ 3.64643000e-01, -5.96278231e-03],\n",
       "        [ 3.77623000e-01, -5.39688843e-03],\n",
       "        [ 3.88543000e-01, -4.91259760e-03],\n",
       "        [ 4.07280000e-01, -4.06422741e-03],\n",
       "        [ 4.18336000e-01, -3.55378204e-03],\n",
       "        [ 4.25623000e-01, -3.21381830e-03],\n",
       "        [ 4.42434000e-01, -2.42068707e-03],\n",
       "        [ 4.52750000e-01, -1.92889855e-03],\n",
       "        [ 4.69732000e-01, -1.11290259e-03],\n",
       "        [ 4.82124000e-01, -5.14825307e-04],\n",
       "        [ 4.91826000e-01, -4.58830472e-05],\n",
       "        [ 5.03536000e-01,  5.20051662e-04],\n",
       "        [ 5.13745000e-01,  1.01084622e-03],\n",
       "        [ 5.26869000e-01,  1.63835548e-03],\n",
       "        [ 5.43241000e-01,  2.41067939e-03],\n",
       "        [ 5.51204000e-01,  2.78129828e-03],\n",
       "        [ 5.67070000e-01,  3.50415703e-03],\n",
       "        [ 5.76825000e-01,  3.93643372e-03],\n",
       "        [ 5.92261000e-01,  4.59927454e-03],\n",
       "        [ 6.02064000e-01,  5.00390036e-03],\n",
       "        [ 6.13586000e-01,  5.46080915e-03],\n",
       "        [ 6.21883000e-01,  5.77577206e-03],\n",
       "        [ 6.36289000e-01,  6.29221286e-03],\n",
       "        [ 6.48318000e-01,  6.68972336e-03],\n",
       "        [ 6.55316000e-01,  6.90596300e-03],\n",
       "        [ 6.66950000e-01,  7.23860846e-03],\n",
       "        [ 6.80618000e-01,  7.58352366e-03],\n",
       "        [ 6.88922000e-01,  7.76706134e-03],\n",
       "        [ 6.99715000e-01,  7.97464210e-03],\n",
       "        [ 7.09525000e-01,  8.13102279e-03],\n",
       "        [ 7.21179000e-01,  8.27519271e-03],\n",
       "        [ 7.30902000e-01,  8.36099227e-03],\n",
       "        [ 7.37360000e-01,  8.39826847e-03],\n",
       "        [ 7.48130000e-01,  8.42810468e-03],\n",
       "        [ 7.58500000e-01,  8.41607931e-03],\n",
       "        [ 7.67948000e-01,  8.37017420e-03],\n",
       "        [ 7.79140000e-01,  8.27178547e-03],\n",
       "        [ 7.83468000e-01,  8.22012377e-03],\n",
       "        [ 7.96294000e-01,  8.02620738e-03],\n",
       "        [ 8.02443000e-01,  7.91118577e-03],\n",
       "        [ 8.14852000e-01,  7.63357268e-03],\n",
       "        [ 8.23606000e-01,  7.40282545e-03],\n",
       "        [ 8.30527000e-01,  7.19973616e-03],\n",
       "        [ 8.44424000e-01,  6.73615874e-03],\n",
       "        [ 8.54839000e-01,  6.33907961e-03],\n",
       "        [ 8.65537000e-01,  5.88493925e-03],\n",
       "        [ 8.76634000e-01,  5.35941118e-03],\n",
       "        [ 8.90771000e-01,  4.60123215e-03],\n",
       "        [ 9.00115000e-01,  4.03663255e-03],\n",
       "        [ 9.14722000e-01,  3.04509772e-03],\n",
       "        [ 9.27686000e-01,  2.07864674e-03],\n",
       "        [ 9.39287000e-01,  1.22023336e-03],\n",
       "        [ 9.50328000e-01,  5.27154780e-04],\n",
       "        [ 9.64174000e-01,  6.14617575e-06],\n",
       "        [ 9.78065000e-01, -2.38995270e-04],\n",
       "        [ 9.93407000e-01, -1.12713592e-03],\n",
       "        [ 1.00000000e+00, -1.91200000e-03]]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d46efc2",
   "metadata": {},
   "source": [
    "## Interpolating between classes with the trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d8fa40bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [188]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m start_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# @param {type:\"slider\", min:0, max:9, step:1}\u001b[39;00m\n\u001b[0;32m     35\u001b[0m end_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# @param {type:\"slider\", min:0, max:9, step:1}\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m fake_images \u001b[38;5;241m=\u001b[39m \u001b[43minterpolate_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_class\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [188]\u001b[0m, in \u001b[0;36minterpolate_class\u001b[1;34m(first_number, second_number)\u001b[0m\n\u001b[0;32m     22\u001b[0m percent_second_label \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, num_interpolation)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     23\u001b[0m percent_second_label \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(percent_second_label, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     24\u001b[0m interpolation_labels \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mfirst_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpercent_second_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msecond_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpercent_second_label\u001b[49m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Combine the noise and the labels and run inference with the generator.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m noise_and_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([interpolation_noise, interpolation_labels], \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Finder22\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1367\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.binary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1363\u001b[0m   \u001b[38;5;66;03m# force_same_dtype=False to preserve existing TF behavior\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m   \u001b[38;5;66;03m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[0;32m   1365\u001b[0m   \u001b[38;5;66;03m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m maybe_promote_tensors(x, y, force_same_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1367\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1369\u001b[0m   \u001b[38;5;66;03m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[39;00m\n\u001b[0;32m   1370\u001b[0m   \u001b[38;5;66;03m# object that can implement the operator with knowledge of itself\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1373\u001b[0m   \u001b[38;5;66;03m# original error from the LHS, because it may be more\u001b[39;00m\n\u001b[0;32m   1374\u001b[0m   \u001b[38;5;66;03m# informative.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(y), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__r\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m op_name):\n",
      "File \u001b[1;32m~\\.conda\\envs\\Finder22\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Finder22\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1700\u001b[0m, in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1698\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops\u001b[38;5;241m.\u001b[39madd(x, y, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   1699\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1700\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Finder22\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:454\u001b[0m, in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    452\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 454\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m    456\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Finder22\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6940\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 6941\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# We first extract the trained generator from our Conditiona GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_interpolation = 9  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))\n",
    "\n",
    "\n",
    "def interpolate_class(first_number, second_number):\n",
    "    # Convert the start and end labels to one-hot encoded vectors.\n",
    "    first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "    second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "    first_label = tf.cast(first_label, tf.float32)\n",
    "    second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "    # Calculate the interpolation vector between the two labels.\n",
    "    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]\n",
    "    percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "    interpolation_labels = (\n",
    "        first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "    )\n",
    "\n",
    "    # Combine the noise and the labels and run inference with the generator.\n",
    "    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    return fake\n",
    "\n",
    "\n",
    "start_class = 1  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "end_class = 5  # @param {type:\"slider\", min:0, max:9, step:1}\n",
    "\n",
    "fake_images = interpolate_class(start_class, end_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "converted_images = tf.image.resize(converted_images, (96, 96)).numpy().astype(np.uint8)\n",
    "imageio.mimsave(\"animation.gif\", converted_images, fps=1)\n",
    "#embed.embed_file(\"animation.gif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669c7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff339c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530ccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1c151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8766f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630b984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb13711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
